{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- saved_model has no hyperparameters (e.g. epochs, batch_size, verbose). \n",
    "- hard coded\n",
    "    - created_at\n",
    "    - created_for\n",
    "    - hyperparameters\n",
    "    _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import jsonschema as jsc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    \"\"\"Reads a JSON file and returns the data.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json(data, file_path):\n",
    "    \"\"\"Writes data to a JSON file.\"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"{file_path} has been created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_input(*inputs):\n",
    "    manual_inputs = {\"created_for_project\": inputs, \"created_at\": inputs}\n",
    "    return manual_inputs\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_parameters_layer(model):\n",
    "    model_config = model.get_config()\n",
    "    del model_config[\"layers\"][0]\n",
    "    model_layers = model.layers\n",
    "\n",
    "    parameter_layers_list = []\n",
    "    layers_dimensions = {}\n",
    "    i = 0\n",
    "    for layer in model_config['layers']:\n",
    "        #pprint(layer)\n",
    "        layer_config_setting = []\n",
    "        for j in layer['config']:\n",
    "            #print(j)\n",
    "            if j not in [\"kernel_initializer\", \"bias_initializer\", \"name\"]:\n",
    "                configuration_setting_dict = {\n",
    "                    \"configuration_setting\": {\n",
    "                        \"configuration_setting_label\": j,\n",
    "                        \"configuration_setting_value\": layer['config'][j],\n",
    "                    }\n",
    "                }\n",
    "                layer_config_setting.append(configuration_setting_dict)\n",
    "        #pprint(layer_config_setting)\n",
    "    \n",
    "        layer_name = layer['config']['name']\n",
    "        layer_type = layer['class_name']\n",
    "\n",
    "        # Use built-in functions for common layer types\n",
    "        if layer_type in {'Conv2D', 'Conv3D', 'Conv1D'}:\n",
    "            dimensions = [layer['config']['filters']] + list(layer['config']['kernel_size'])\n",
    "        elif layer_type == 'Dense':\n",
    "            dimensions = [layer['config']['units']]\n",
    "        elif layer_type == 'LSTM':\n",
    "            dimensions = list(layer['config']['units'])\n",
    "        elif layer_type == 'Embedding':\n",
    "            dimensions = list(layer['config']['input_dim'])\n",
    "        elif layer_type == 'Flatten':\n",
    "            dimensions = 1 \n",
    "        elif layer_type == 'MaxPooling2D' or layer_type == 'MaxPooling3D':\n",
    "            dimensions = list(layer['config']['pool_size'])\n",
    "        elif layer_type == 'AveragePooling2D' or layer_type == 'AveragePooling3D':\n",
    "            dimensions = list(layer['config']['pool_size'])\n",
    "\n",
    "        # Check for potentially nested configurations like Recurrent layers\n",
    "        elif 'rnn' in layer_type.lower():\n",
    "            try:\n",
    "                dimensions = layer['layers'][0]['units']\n",
    "            except KeyError:\n",
    "                dimensions = None  # Handle nested layers recursively\n",
    "\n",
    "        # Handle unsupported layer types\n",
    "        else:\n",
    "            dimensions = None\n",
    "\n",
    "        if dimensions:\n",
    "            layers_dimensions[layer_name] = dimensions\n",
    "\n",
    "        parameter_layer = {\n",
    "            \"parameter_layer\": {\n",
    "                \"layer_configuration\": layer_config_setting,\n",
    "                \"layer_dimension\": dimensions,\n",
    "                \"layer_input_dimension\": list(model_layers[i].input_shape),\n",
    "            },\n",
    "            \"layer_type\": f\"{layer['class_name']}\",\n",
    "        }\n",
    "        i += 1\n",
    "        parameter_layers_list.append(parameter_layer)\n",
    "\n",
    "\n",
    "    return parameter_layers_list\n",
    "    \n",
    "\n",
    "def get_training_config(model):\n",
    "    model_optimizer_config = model.optimizer.get_config()\n",
    "    optimizer_name = model.optimizer.get_config()['name']\n",
    "    model_optimizer_config.pop('name')\n",
    "    model_hyperparameter_config = {\"epoch\":10, \"batch_size\": 128, \"verbose\":1}\n",
    "    training_config = {}\n",
    "    hyperparameters_configuration_list = []\n",
    "    \n",
    "    for i in model_hyperparameter_config:\n",
    "        configuration_setting_dict = {\n",
    "            \"configuration_setting\": {\n",
    "                \"configuration_setting_label\": i,\n",
    "                \"configuration_setting_value\": model_hyperparameter_config[i],\n",
    "            }\n",
    "        }\n",
    "        hyperparameters_configuration_list.append(configuration_setting_dict)\n",
    "        hyperparameters = hyperparameters_configuration_list\n",
    "    \n",
    "\n",
    "    optimizers_configuration_list = []\n",
    "    for i in model_optimizer_config:\n",
    "        configuration_setting_dict = {\n",
    "            \"configuration_setting\": {\n",
    "                \"configuration_setting_label\": i,\n",
    "                \"configuration_setting_value\": model_optimizer_config[i],\n",
    "            }\n",
    "        }\n",
    "        optimizers_configuration_list.append(configuration_setting_dict)\n",
    "\n",
    "        # pprint(layer_config_setting)\n",
    "        # print(i)\n",
    "        # layer_config.append(config_setting)\n",
    "    optimizer = {\n",
    "        \"optimizer_name\": optimizer_name,\n",
    "        \"opimizer_configuration\": optimizers_configuration_list,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #parameter_layers_list.append(parameter_layer)\n",
    "\n",
    "    return hyperparameters, optimizer\n",
    "\n",
    "\n",
    "def get_initializer(model):\n",
    "    model_config = model.get_config()\n",
    "    model_initializers_list = []\n",
    "\n",
    "    for i in range(len(model_config[\"layers\"])):\n",
    "        try:\n",
    "            for k in [\"kernel_initializer\", \"bias_initializer\"]:\n",
    "                init_config_setting = []\n",
    "                for j in model_config[\"layers\"][i][\"config\"][k][\"config\"]:\n",
    "                    configuration_setting_dict = {\n",
    "                        \"configuration_setting\": {\n",
    "                            \"configuration_setting_label\": j,\n",
    "                            \"configuration_setting_value\": model_config[\"layers\"][i][\n",
    "                                \"config\"\n",
    "                            ][k][\"config\"][j],\n",
    "                        }\n",
    "                    }\n",
    "                    # print(configuration_setting_dict)\n",
    "                    init_config_setting.append(configuration_setting_dict)\n",
    "\n",
    "                model_initializer = {\n",
    "                    \"initializer_name\": f\"{model_config ['layers'][i]['config'][k]['class_name']}\",\n",
    "                    \"configuration_setting\": init_config_setting,\n",
    "                    \"whole_model\": False,\n",
    "                    \"initializes_layer_index\": i,\n",
    "                }\n",
    "                model_initializers_list.append(model_initializer)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return model_initializers_list\n",
    "\n",
    "\n",
    "def get_meta_data(model_path, framework, *inputs):\n",
    "    # if framework not in frameworks:\n",
    "    #     raise ValueError(\"Invalid sim type. Expected one of: %s\" % frameworks)\n",
    "    model = load_model(model_path)\n",
    "    if framework == \"tensorflow\":\n",
    "        model_name = os.path.basename(model_path)\n",
    "        model_location = os.getcwd()\n",
    "        hyperparameter_config, optimizer_config = get_training_config(model)\n",
    "        \n",
    "        manual_inputs = get_manual_input(inputs)\n",
    "        parameters_layers = get_parameters_layer(model)\n",
    "        input_parameters_layers = model.get_config()[\"layers\"][0][\"config\"]\n",
    "        initializer = get_initializer(model)\n",
    "        mllo = {\n",
    "            \"model_name\": f\"{model_name}\",\n",
    "            \"model_type\": f\"{model.name}\",\n",
    "            \"model_framework\": {\n",
    "                \"framework_name\": \"tensorflow\",\n",
    "                \"framework_version\": f\"{model.tensorflow_version}\",\n",
    "            },\n",
    "            \"model_location\": f\"{model_location}\",\n",
    "            \"created_at\": \"2024-1-1\",\n",
    "            \"created_for_project\": \"MLLOS\",\n",
    "            \"model_input_requirements\": {\n",
    "                \"input_dimension\": input_parameters_layers[\"batch_input_shape\"],\n",
    "                \"input_datatype\": input_parameters_layers[\"dtype\"],\n",
    "            },\n",
    "            \"model_architecture\": {\"parameters\": parameters_layers},\n",
    "            \"training_configuration\": {\n",
    "                \"hyperparameters\": hyperparameter_config,\n",
    "                \"optimizer\": optimizer_config,\n",
    "            },\n",
    "            \"model_initializers\": initializer,\n",
    "        }\n",
    "    return mllo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mllo_mapped_2024-01-12T13_34_32404128.json has been created\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "str_time = datetime.now()\n",
    "d = datetime.strftime(str_time, \"%Y-%m-%dT%H_%M_%S%f\")\n",
    "filepath = \"toy_model\"\n",
    "filename = f\"mllo_mapped_{d}.json\"\n",
    "model_dict = get_meta_data(filepath, framework=\"tensorflow\")\n",
    "write_json(model_dict, file_path= filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load mllo_mapped_2024-01-12T13_22_47944391.json\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "f = open(\"ml3.json\")\n",
    "jsonsch = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(filename)\n",
    "print(f\"load {filename}\")\n",
    "loaded_json = json.load(f)\n",
    "f.close()\n",
    "\n",
    "jsc.validate(loaded_json, jsonsch)\n",
    "print('pass')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
